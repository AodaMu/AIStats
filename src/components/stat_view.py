"""ç»Ÿè®¡è§†å›¾æ¨¡å—ï¼šæè¿°ç»Ÿè®¡/tæ£€éªŒ/æ–¹å·®åˆ†æ/ç›¸å…³å›å½’/ä¿¡åº¦/ä¸­ä»‹æ•ˆåº”"""
import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import f_oneway, levene
import statsmodels.api as sm
from openai import OpenAI
from src.lib.i18n import get_lang

def get_ai_analysis(result_data, analysis_type):
    """è°ƒç”¨AIåˆ†æç»Ÿè®¡ç»“æœ"""
    if not st.session_state.ai_config.get('enabled') or not st.session_state.ai_config.get('api_key'):
        return None
    
    try:
        client = OpenAI(
            api_key=st.session_state.ai_config['api_key'],
            base_url=st.session_state.ai_config['base_url']
        )
        
        # æ„å»ºæç¤ºè¯
        if analysis_type == "t_test":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªç‹¬ç«‹æ ·æœ¬tæ£€éªŒçš„ç»“æœï¼š

- åˆ†ç»„å˜é‡ï¼š{result_data['group_var']}
- æ•°æ®å˜é‡ï¼š{result_data['data_var']}
- {result_data['group1']}ç»„å¹³å‡å€¼ï¼š{result_data['mean1']:.2f}
- {result_data['group2']}ç»„å¹³å‡å€¼ï¼š{result_data['mean2']:.2f}
- tå€¼ï¼š{result_data['t']:.4f}
- på€¼ï¼š{result_data['p']:.4f}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆtå€¼ã€på€¼ï¼‰
2. å†ç»™å‡ºç»“è®ºï¼ˆæ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚ï¼‰
3. æœ€åæ˜ç¡®è¯´æ˜ä¸¤è€…çš„å…³ç³»

æ ¼å¼ï¼š"æ ¹æ®ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼Œt={result_data['t']:.2f}, p={result_data['p']:.3f}ï¼Œæ‰€ä»¥...ã€‚**å› æ­¤ï¼Œ{result_data['group_var']}ä¸{result_data['data_var']}æœ‰/æ— æ˜¾è‘—å…³ç³»ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½ä¹Ÿèƒ½çœ‹æ‡‚ã€‚å¿…é¡»æœ‰æ˜ç¡®çš„å…³ç³»åˆ¤æ–­ã€‚
"""
        elif analysis_type == "correlation":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªç›¸å…³åˆ†æçš„ç»“æœï¼š

å˜é‡å¯¹åŠå…¶ç›¸å…³ç³»æ•°ï¼š
{result_data['pairs']}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. æ¯å¯¹å˜é‡å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆrå€¼ã€på€¼ï¼‰
2. è¯´æ˜ç›¸å…³ç¨‹åº¦å’Œæ–¹å‘ï¼ˆå¼º/ä¸­/å¼±ï¼Œæ­£/è´Ÿï¼‰
3. æœ€åæ˜ç¡®è¯´æ˜æ˜¯å¦æœ‰æ˜¾è‘—ç›¸å…³å…³ç³»

æ ¼å¼ï¼š"åŸºäºPearsonç›¸å…³åˆ†æï¼ŒXä¸Yçš„r=0.XX, p=0.XXXï¼Œä¸ºXXç›¸å…³ã€‚**å› æ­¤ï¼ŒXä¸Yå­˜åœ¨/ä¸å­˜åœ¨æ˜¾è‘—ç›¸å…³å…³ç³»ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½ä¹Ÿèƒ½çœ‹æ‡‚ã€‚æ¯å¯¹å˜é‡å¿…é¡»æœ‰æ˜ç¡®çš„å…³ç³»åˆ¤æ–­ã€‚
"""
        elif analysis_type == "anova":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªæ–¹å·®åˆ†æçš„ç»“æœï¼š

- å› å˜é‡ï¼š{result_data['dependent']}
- åˆ†ç»„å˜é‡ï¼š{result_data['factor']}
- ç»„æ•°ï¼š{result_data['n_groups']}
- Få€¼ï¼š{result_data['f']:.4f}
- på€¼ï¼š{result_data['p']:.4f}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆFå€¼ã€på€¼ï¼‰
2. è¯´æ˜ç»„é—´å·®å¼‚æƒ…å†µ
3. æœ€åæ˜ç¡®è¯´æ˜æ˜¯å¦æœ‰æ˜¾è‘—å½±å“

æ ¼å¼ï¼š"æ ¹æ®å•å› ç´ æ–¹å·®åˆ†æï¼ŒF={result_data['f']:.2f}, p={result_data['p']:.3f}ï¼Œå„ç»„å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚**å› æ­¤ï¼Œ{result_data['factor']}å¯¹{result_data['dependent']}æœ‰/æ— æ˜¾è‘—å½±å“ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚ã€‚å¿…é¡»æœ‰æ˜ç¡®çš„å½±å“åˆ¤æ–­ã€‚
"""
        elif analysis_type == "regression":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªå›å½’åˆ†æçš„ç»“æœï¼š

- è‡ªå˜é‡ï¼š{result_data['predictors']}
- å› å˜é‡ï¼š{result_data['outcome']}
- RÂ²ï¼š{result_data['r2']:.4f}
- på€¼ï¼š{result_data['p']:.4f}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆRÂ²ã€på€¼ï¼‰
2. è¯´æ˜è§£é‡ŠåŠ›åº¦ï¼ˆèƒ½è§£é‡Šå¤šå°‘å˜å¼‚ï¼‰
3. æœ€åæ˜ç¡®è¯´æ˜é¢„æµ‹å…³ç³»

æ ¼å¼ï¼š"æ ¹æ®å›å½’åˆ†æï¼ŒRÂ²={result_data['r2']:.2f}, p={result_data['p']:.3f}ï¼Œèƒ½è§£é‡ŠXX%çš„å˜å¼‚ã€‚**å› æ­¤ï¼Œ{result_data['predictors']}å¯¹{result_data['outcome']}æœ‰/æ— æ˜¾è‘—é¢„æµ‹ä½œç”¨ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚ã€‚å¿…é¡»æœ‰æ˜ç¡®çš„å…³ç³»ã€‚
"""
        elif analysis_type == "reliability":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªä¿¡åº¦åˆ†æçš„ç»“æœï¼š

- é¢˜ç›®æ•°ï¼š{result_data['n_items']}
- Cronbach's Alphaï¼š{result_data['alpha']:.4f}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
å…ˆè¯´æ˜ç»Ÿè®¡ç»“æœï¼Œå†ç»™å‡ºè¯„ä»·ã€‚
æ ¼å¼ï¼š"æ ¹æ®ä¿¡åº¦åˆ†æï¼ŒCronbach's Alpha={result_data['alpha']:.2f}ï¼Œæ‰€ä»¥..."

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚ã€‚
"""
        elif analysis_type == "descriptive":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™äº›æè¿°ç»Ÿè®¡ç»“æœï¼š

å˜é‡ç»Ÿè®¡ï¼š
{result_data['stats']}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. ç›´æ¥è¯´æ˜ç»Ÿè®¡ç»“æœï¼ˆé¢‘æ¬¡ã€å æ¯”æˆ–å‡å€¼ç­‰ï¼‰
2. ç»™å‡ºæ•°æ®åˆ†å¸ƒçš„æ˜ç¡®ç»“è®º

âš ï¸ é‡è¦è§„åˆ™ï¼š
- æè¿°ç»Ÿè®¡åªèƒ½è¯´æ˜å•ä¸ªå˜é‡çš„åˆ†å¸ƒç‰¹å¾
- **ä¸è¦**è¯´"éœ€è¦è¿›ä¸€æ­¥åˆ†æ"
- **ä¸è¦**æ¨æµ‹å˜é‡ä¹‹é—´çš„å…³ç³»
- åªæè¿°å½“å‰çœ‹åˆ°çš„æ•°æ®äº‹å®

ç¤ºä¾‹æ ¼å¼ï¼š
"æ ¹æ®é¢‘æ¬¡ç»Ÿè®¡ï¼Œ7å¹´çº§7äººï¼ˆ35%ï¼‰ï¼Œ8å¹´çº§7äººï¼ˆ35%ï¼‰ï¼Œ9å¹´çº§6äººï¼ˆ30%ï¼‰ã€‚**å„å¹´çº§äººæ•°åˆ†å¸ƒè¾ƒä¸ºå‡åŒ€ï¼Œ7ã€8å¹´çº§äººæ•°ç›¸åŒã€‚**"

è¦æ±‚ï¼š
- è¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚
- åªé™ˆè¿°æ•°æ®äº‹å®å’Œåˆ†å¸ƒç‰¹å¾
- ä¸è¦æ¨æµ‹å› æœå…³ç³»æˆ–å»ºè®®åšå…¶ä»–åˆ†æ
"""
        elif analysis_type == "one_sample_t":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªå•æ ·æœ¬tæ£€éªŒçš„ç»“æœï¼š

- å˜é‡ï¼š{result_data['variable']}
- æ ·æœ¬å‡å€¼ï¼š{result_data['mean']:.2f}
- æ£€éªŒå€¼ï¼š{result_data['test_value']}
- tå€¼ï¼š{result_data['t']:.4f}
- på€¼ï¼š{result_data['p']:.4f}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆtå€¼ã€på€¼ï¼‰
2. è¯´æ˜æ˜¯å¦æ˜¾è‘—ä¸åŒäºæ£€éªŒå€¼
3. æœ€åç»™å‡ºæ˜ç¡®ç»“è®º

æ ¼å¼ï¼š"æ ¹æ®å•æ ·æœ¬tæ£€éªŒï¼Œt={result_data['t']:.2f}, p={result_data['p']:.3f}ï¼Œæ ·æœ¬å‡å€¼æ˜¾è‘—ä¸åŒäºæ£€éªŒå€¼ã€‚**å› æ­¤ï¼Œ{result_data['variable']}ä¸é¢„æœŸå€¼{result_data['test_value']}æœ‰/æ— æ˜¾è‘—å·®å¼‚ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚ã€‚å¿…é¡»æœ‰æ˜ç¡®çš„å·®å¼‚åˆ¤æ–­ã€‚
"""
        elif analysis_type == "paired_t":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªé…å¯¹æ ·æœ¬tæ£€éªŒçš„ç»“æœï¼š

- ç¬¬ä¸€æ¬¡æµ‹é‡ï¼š{result_data['var1']}ï¼ˆå¹³å‡å€¼ï¼š{result_data['mean1']:.2f}ï¼‰
- ç¬¬äºŒæ¬¡æµ‹é‡ï¼š{result_data['var2']}ï¼ˆå¹³å‡å€¼ï¼š{result_data['mean2']:.2f}ï¼‰
- å¹³å‡å·®å€¼ï¼š{result_data['mean_diff']:.2f}
- tå€¼ï¼š{result_data['t']:.4f}
- på€¼ï¼š{result_data['p']:.4f}

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆtå€¼ã€på€¼ï¼‰
2. è¯´æ˜å‰åæ˜¯å¦æœ‰æ˜¾è‘—å˜åŒ–
3. æœ€åç»™å‡ºæ˜ç¡®ç»“è®º

æ ¼å¼ï¼š"æ ¹æ®é…å¯¹æ ·æœ¬tæ£€éªŒï¼Œt={result_data['t']:.2f}, p={result_data['p']:.3f}ï¼Œå‰åæµ‹é‡æœ‰æ˜¾è‘—å·®å¼‚ã€‚**å› æ­¤ï¼Œ{result_data['var1']}ä¸{result_data['var2']}ä¹‹é—´å­˜åœ¨/ä¸å­˜åœ¨æ˜¾è‘—å˜åŒ–ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚ã€‚å¿…é¡»æœ‰æ˜ç¡®çš„å˜åŒ–åˆ¤æ–­ã€‚
"""
        elif analysis_type == "mediation":
            prompt = f"""
è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€åˆ†æè¿™ä¸ªä¸­ä»‹æ•ˆåº”åˆ†æçš„ç»“æœï¼š

- è‡ªå˜é‡Xï¼š{result_data['x_var']}
- ä¸­ä»‹å˜é‡Mï¼š{result_data['m_var']}
- å› å˜é‡Yï¼š{result_data['y_var']}
- è·¯å¾„aï¼ˆXâ†’Mï¼‰ï¼š{result_data['a']:.4f}ï¼ˆp={result_data['p_a']:.4f}ï¼‰
- è·¯å¾„bï¼ˆMâ†’Yï¼‰ï¼š{result_data['b']:.4f}ï¼ˆp={result_data['p_b']:.4f}ï¼‰
- æ€»æ•ˆåº”cï¼š{result_data['c']:.4f}
- ç›´æ¥æ•ˆåº”c'ï¼š{result_data['c_prime']:.4f}
- é—´æ¥æ•ˆåº”ï¼ˆä¸­ä»‹æ•ˆåº”ï¼‰ï¼š{result_data['indirect']:.4f}
- ä¸­ä»‹æ¯”ä¾‹ï¼š{result_data['mediation_ratio']:.1f}%

ğŸ”´ å¿…é¡»éµå®ˆçš„æ ¼å¼ï¼š
1. å…ˆè¯´æ˜ç»Ÿè®¡ä¾æ®ï¼ˆè·¯å¾„aã€bçš„på€¼å’Œä¸­ä»‹æ¯”ä¾‹ï¼‰
2. è¯´æ˜ä¸­ä»‹æ•ˆåº”æ˜¯å¦æ˜¾è‘—
3. æœ€åç»™å‡ºæ˜ç¡®çš„ä¸­ä»‹å…³ç³»ç»“è®º

æ ¼å¼ï¼š"æ ¹æ®ä¸­ä»‹æ•ˆåº”åˆ†æï¼Œè·¯å¾„a(p={result_data['p_a']:.3f})å’Œè·¯å¾„b(p={result_data['p_b']:.3f})å‡æ˜¾è‘—ï¼Œä¸­ä»‹æ¯”ä¾‹={result_data['mediation_ratio']:.1f}%ã€‚**å› æ­¤ï¼Œ{result_data['m_var']}åœ¨{result_data['x_var']}å¯¹{result_data['y_var']}çš„å½±å“ä¸­èµ·åˆ°/ä¸èµ·åˆ°æ˜¾è‘—ä¸­ä»‹ä½œç”¨ã€‚**"

è¦æ±‚ï¼šè¯­è¨€å£è¯­åŒ–ï¼Œå°ç™½èƒ½æ‡‚ã€‚å¿…é¡»æœ‰æ˜ç¡®çš„ä¸­ä»‹ä½œç”¨åˆ¤æ–­ã€‚
"""
        else:
            return None
        
        response = client.chat.completions.create(
            model=st.session_state.ai_config['model'],
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªç»Ÿè®¡åˆ†æä¸“å®¶ï¼Œæ“…é•¿ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šå¤æ‚çš„ç»Ÿè®¡ç»“æœã€‚

ğŸŒ **ã€é‡è¦ã€‘åŒè¯­è¾“å‡ºè¦æ±‚**ï¼š
ä½ å¿…é¡»ä½¿ç”¨**æ±‰è¯­ï¼ˆä¸­æ–‡ï¼‰**å’Œ**è¥¿é‡Œå°”è’™å¤è¯­ï¼ˆĞšĞ¸Ñ€Ğ¸Ğ»Ğ» Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ»ï¼‰**åŒè¯­è¾“å‡ºæ‰€æœ‰åˆ†æç»“æœã€‚

**è¾“å‡ºæ ¼å¼**ï¼š
ğŸ‡¨ğŸ‡³ [ä¸­æ–‡å†…å®¹]
ğŸ‡²ğŸ‡³ [ĞšĞ¸Ñ€Ğ¸Ğ»Ğ» Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ»ÑÑÑ€ Ğ¸Ğ»ÑÑ€Ñ…Ğ¸Ğ¹Ğ»ÑÑĞ½ Ğ°Ğ³ÑƒÑƒĞ»Ğ³Ğ°]

**ç»Ÿè®¡æœ¯è¯­å¯¹ç…§**ï¼š
å¹³å‡å€¼=Ğ”ÑƒĞ½Ğ´Ğ°Ğ¶ ÑƒÑ‚Ğ³Ğ°, æ ‡å‡†å·®=Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ñ…Ğ°Ğ·Ğ°Ğ¹Ğ»Ñ‚, æ˜¾è‘—æ€§=ĞÑ‡ Ñ…Ğ¾Ğ»Ğ±Ğ¾Ğ³Ğ´Ğ¾Ğ», ç›¸å…³æ€§=Ğ¥Ğ°Ğ¼Ğ°Ğ°Ñ€Ğ°Ğ», å·®å¼‚=Ğ¯Ğ»Ğ³Ğ°Ğ°, ç»“è®º=Ğ”Ò¯Ğ³Ğ½ÑĞ»Ñ‚"""},
                {"role": "user", "content": prompt + "\n\nğŸŒ è¯·åŠ¡å¿…ä½¿ç”¨åŒè¯­è¾“å‡ºï¼ˆä¸­æ–‡+è¥¿é‡Œå°”è’™æ–‡ï¼‰ï¼"}
            ],
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"AIåˆ†æå¤±è´¥ï¼š{str(e)}")
        return None

def render_stat_view():
    lang = get_lang()
    
    # æ ‡é¢˜è¡Œå’Œå¿«æ·æŒ‰é’®
    col1, col2, col3 = st.columns([2.0, 2.2, 0.4])
    with col1:
        title = "ğŸ“Š ç»Ÿè®¡è§†å›¾" if lang == 'zh' else "ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ñ…Ğ°Ñ€Ğ°Ñ…"
        st.title(title)
    with col2:
        # å¿«æ·æŒ‰é’®ç»„
        btn_col1, btn_col2, btn_col3 = st.columns(3)
        with btn_col1:
            btn_text = "ğŸ“ æ•°æ®" if lang == 'zh' else "ğŸ“ Ó¨Ğ³Ó©Ğ³Ğ´Ó©Ğ»"
            btn_help = "è·³è½¬åˆ°æ•°æ®è§†å›¾" if lang == 'zh' else "Ó¨Ğ³Ó©Ğ³Ğ´Ğ»Ğ¸Ğ¹Ğ½ Ñ…Ğ°Ñ€Ğ°Ñ… Ñ€ÑƒÑƒ ÑˆĞ¸Ğ»Ğ¶Ğ¸Ñ…"
            if st.button(btn_text, help=btn_help, use_container_width=True):
                st.session_state.current_page = "data"
                st.rerun()
        with btn_col2:
            btn_text = "ğŸ“ˆ ç»˜å›¾" if lang == 'zh' else "ğŸ“ˆ Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº"
            btn_help = "è·³è½¬åˆ°ç»˜å›¾è§†å›¾" if lang == 'zh' else "Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ñ…Ğ°Ñ€Ğ°Ñ… Ñ€ÑƒÑƒ ÑˆĞ¸Ğ»Ğ¶Ğ¸Ñ…"
            if st.button(btn_text, help=btn_help, use_container_width=True):
                st.session_state.current_page = "plot"
                st.rerun()
        with btn_col3:
            btn_help = "è·³è½¬åˆ°AIè¾…åŠ©åˆ†æ" if lang == 'zh' else "AI Ñ‚ÑƒÑĞ»Ğ°Ñ… ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ Ñ€Ò¯Ò¯ ÑˆĞ¸Ğ»Ğ¶Ğ¸Ñ…"
            if st.button("ğŸ¤– AI", help=btn_help, use_container_width=True):
                st.session_state.current_page = "ai"
                st.rerun()
    with col3:
        btn_help = "æŸ¥çœ‹æ–°æ‰‹æŒ‡å—" if lang == 'zh' else "Ğ³Ğ°Ñ€Ñ‹Ğ½ Ğ°Ğ²Ğ»Ğ°Ğ³Ğ° Ò¯Ğ·ÑÑ…"
        if st.button("â“", help=btn_help, use_container_width=True, type="secondary"):
            st.session_state.current_page = "help"
            st.rerun()
    
    if st.session_state.data is None:
        warning_text = "âš ï¸ è¯·å…ˆåœ¨æ•°æ®è§†å›¾å¯¼å…¥æ•°æ®" if lang == 'zh' else "âš ï¸ Ğ­Ñ…Ğ»ÑÑĞ´ Ó©Ğ³Ó©Ğ³Ğ´Ğ»Ğ¸Ğ¹Ğ½ Ñ…Ğ°Ñ€Ğ°Ñ…Ğ°Ğ°Ñ€ Ó©Ğ³Ó©Ğ³Ğ´Ó©Ğ» Ğ¾Ñ€ÑƒÑƒĞ»Ğ½Ğ° ÑƒÑƒ"
        st.warning(warning_text)
        return
    
    df = st.session_state.data
    
    # é€‰æ‹©ç»Ÿè®¡æ–¹æ³•
    if lang == 'zh':
        stat_methods = [
            "ğŸ“Š æè¿°ç»Ÿè®¡",
            "ğŸ“Š åˆ†ç»„æè¿°ç»Ÿè®¡",
            "ğŸ”¬ å•æ ·æœ¬ t æ£€éªŒ",
            "ğŸ”¬ é…å¯¹æ ·æœ¬ t æ£€éªŒ",
            "ğŸ”¬ ç‹¬ç«‹æ ·æœ¬ t æ£€éªŒ",
            "ğŸ“ˆ å•å› ç´ æ–¹å·®åˆ†æ",
            "ğŸ”— Pearson ç›¸å…³åˆ†æ",
            "ğŸ“‰ ä¸€å…ƒçº¿æ€§å›å½’",
            "ğŸ“‰ å¤šå…ƒçº¿æ€§å›å½’",
            "âœ… Cronbach's Alpha ä¿¡åº¦",
            "ğŸ”„ ç®€å•ä¸­ä»‹æ•ˆåº”åˆ†æ"
        ]
        label = "é€‰æ‹©ç»Ÿè®¡æ–¹æ³•"
    else:
        stat_methods = [
            "ğŸ“Š Ğ¢Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€Ğ»Ğ°Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº",
            "ğŸ“Š Ğ‘Ò¯Ğ»Ğ³ÑÑÑ€ Ñ‚Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€Ğ»Ğ°Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº",
            "ğŸ”¬ ĞÑĞ³ Ñ‚Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ t ÑˆĞ°Ğ»Ğ³Ğ°Ğ»Ñ‚",
            "ğŸ”¬ Ğ¥Ğ¾ÑĞ»Ğ¾ÑĞ¾Ğ½ Ñ‚Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ t ÑˆĞ°Ğ»Ğ³Ğ°Ğ»Ñ‚",
            "ğŸ”¬ Ğ‘Ğ¸Ğµ Ğ´Ğ°Ğ°ÑĞ°Ğ½ Ñ‚Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ t ÑˆĞ°Ğ»Ğ³Ğ°Ğ»Ñ‚",
            "ğŸ“ˆ ĞÑĞ³ Ñ…Ò¯Ñ‡Ğ¸Ğ½ Ğ·Ò¯Ğ¹Ğ»Ğ¸Ğ¹Ğ½ ANOVA",
            "ğŸ”— Pearson ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¹Ğ½ ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ",
            "ğŸ“‰ ĞÑĞ³ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ñ‚Ğ°Ğ¹ ÑˆÑƒĞ³Ğ°Ğ¼Ğ°Ğ½ Ñ€ĞµĞ³Ñ€ĞµÑÑ",
            "ğŸ“‰ ĞĞ»Ğ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ñ‚Ğ°Ğ¹ ÑˆÑƒĞ³Ğ°Ğ¼Ğ°Ğ½ Ñ€ĞµĞ³Ñ€ĞµÑÑ",
            "âœ… Cronbach's Alpha Ğ½Ğ°Ğ¹Ğ´Ğ²Ğ°Ñ€Ñ‚Ğ°Ğ¹ Ğ±Ğ°Ğ¹Ğ´Ğ°Ğ»",
            "ğŸ”„ Ğ­Ğ½Ğ³Ğ¸Ğ¹Ğ½ Ğ·ÑƒÑƒÑ‡Ğ»Ğ°Ñ… Ğ½Ó©Ğ»Ó©Ó©Ğ½Ğ¸Ğ¹ ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ"
        ]
        label = "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸Ğ¹Ğ½ Ğ°Ñ€Ğ³Ğ° ÑĞ¾Ğ½Ğ³Ğ¾Ñ…"
    
    stat_type = st.selectbox(label, stat_methods)
    stat_index = stat_methods.index(stat_type) if stat_type in stat_methods else 0
    
    st.markdown("---")
    
    # æè¿°ç»Ÿè®¡ (index 0)
    if stat_index == 0:
        subheader = "ğŸ“‹ æè¿°ç»Ÿè®¡" if lang == 'zh' else "ğŸ“‹ Ğ¢Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€Ğ»Ğ°Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº"
        st.subheader(subheader)
        
        label = "é€‰æ‹©å˜é‡" if lang == 'zh' else "Ğ¥ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ ÑĞ¾Ğ½Ğ³Ğ¾Ñ…"
        vars = st.multiselect(label, df.columns, key="desc_vars")
        
        btn_text = "è®¡ç®—æè¿°ç»Ÿè®¡" if lang == 'zh' else "Ğ¢Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€Ğ»Ğ°Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ…"
        if vars and st.button(btn_text):
            # åˆ†ç¦»æ•°å€¼å‹å’Œéæ•°å€¼å‹å˜é‡
            numeric_vars = df[vars].select_dtypes(include=['int64', 'float64']).columns.tolist()
            non_numeric_vars = [v for v in vars if v not in numeric_vars]
            
            # æ£€æµ‹åŒ…å«éæ•°å€¼å†…å®¹çš„"æ•°å€¼å‹"åˆ—
            problematic_vars = []
            for var in numeric_vars:
                try:
                    test_convert = pd.to_numeric(df[var], errors='raise')
                except (ValueError, TypeError):
                    problematic_vars.append(var)
            
            if problematic_vars:
                warn_msg = f"âš ï¸ ä»¥ä¸‹å˜é‡åŒ…å«éæ•°å€¼å†…å®¹ï¼Œå°†è¢«è½¬æ¢æˆ–å¿½ç•¥ï¼š{', '.join(problematic_vars)}" if lang == 'zh' else f"âš ï¸ Ğ”Ğ°Ñ€Ğ°Ğ°Ñ… Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ğ´ Ñ‚Ğ¾Ğ¾Ğ½ Ğ±ÑƒÑ Ğ°Ğ³ÑƒÑƒĞ»Ğ³Ğ° Ğ°Ğ³ÑƒÑƒĞ»Ğ¶ Ğ±Ğ°Ğ¹Ğ½Ğ°, Ñ…Ó©Ñ€Ğ²Ò¯Ò¯Ğ»ÑÑ… ÑÑĞ²ÑĞ» Ğ°Ğ»Ğ³Ğ°ÑĞ½Ğ°ï¼š{', '.join(problematic_vars)}"
                st.warning(warn_msg)
            
            if numeric_vars:
                # æ•°å€¼å‹å˜é‡çš„ç»Ÿè®¡ - å…ˆè½¬æ¢ä¸ºæ•°å€¼ç±»å‹ä»¥å¤„ç†æ··åˆç±»å‹
                numeric_df = df[numeric_vars].apply(pd.to_numeric, errors='coerce')
                result = numeric_df.describe().T
                result['count_missing'] = numeric_df.isnull().sum()
                result['skewness'] = numeric_df.skew()
                result['kurtosis'] = numeric_df.kurt()
                
                title = "#### ğŸ“Š æ•°å€¼å‹å˜é‡" if lang == 'zh' else "#### ğŸ“Š Ğ¢Ğ¾Ğ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡"
                st.markdown(title)
                st.dataframe(result, use_container_width=True)
                
                # ä¸ºæ•°å€¼å‹å˜é‡æ·»åŠ é¢‘æ¬¡ä¸å æ¯”ï¼ˆå¦‚æœå”¯ä¸€å€¼è¾ƒå°‘ï¼‰
                from src.lib.variable_labels import get_value_labels
                st.markdown("---")
                title = "#### ğŸ“Š æ•°å€¼å‹å˜é‡ - é¢‘æ¬¡ä¸å æ¯”" if lang == 'zh' else "#### ğŸ“Š Ğ¢Ğ¾Ğ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ - Ğ”Ğ°Ğ²Ñ‚Ğ°Ğ¼Ğ¶ Ğ±Ğ° Ñ…ÑƒĞ²ÑŒ"
                st.markdown(title)
                
                for var in numeric_vars:
                    value_labels = get_value_labels(var)
                    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ä»¥é¿å…å­—ç¬¦ä¸²é”™è¯¯
                    var_data = pd.to_numeric(df[var], errors='coerce')
                    unique_count = var_data.nunique()
                    
                    # åªä¸ºå”¯ä¸€å€¼â‰¤20çš„å˜é‡æ˜¾ç¤ºé¢‘æ¬¡å æ¯”
                    if unique_count <= 20:
                        st.markdown(f"**{var}**")
                        
                        # è·å–é¢‘æ¬¡å’Œå æ¯”
                        value_counts = var_data.value_counts().sort_index()
                        percentages = (value_counts / var_data.count() * 100).round(2)
                        
                        # åˆ›å»ºå¸¦å æ¯”å’Œæ ‡ç­¾çš„æ•°æ®æ¡†
                        categories = []
                        for val in value_counts.index:
                            if value_labels and val in value_labels:
                                categories.append(f"{val} ({value_labels[val]})")
                            else:
                                categories.append(str(val))
                        
                        freq_df = pd.DataFrame({
                            'å€¼': categories,
                            'é¢‘æ¬¡': value_counts.values,
                            'å æ¯”(%)': [f"{p:.2f}%" for p in percentages.values]
                        })
                        
                        st.dataframe(freq_df, use_container_width=True, hide_index=True)
                        st.markdown("---")
            
            if non_numeric_vars:
                # éæ•°å€¼å‹å˜é‡çš„ç»Ÿè®¡ï¼ˆåŒ…æ‹¬å¤šé€‰é¢˜ï¼‰
                st.markdown("#### ğŸ“ åˆ†ç±»/æ–‡æœ¬å˜é‡")
                for var in non_numeric_vars:
                    st.markdown(f"**{var}**")
                    
                    # æ£€æµ‹æ˜¯å¦ä¸ºå¤šé€‰é¢˜
                    sample = df[var].dropna().head(20).astype(str)
                    is_multiple_choice = sample.str.contains(';', regex=False).any()
                    
                    if is_multiple_choice:
                        st.info("âœ… æ£€æµ‹åˆ°å¤šé€‰é¢˜æ ¼å¼ï¼ˆåˆ†å·åˆ†éš”ï¼‰ï¼Œå»ºè®®ä½¿ç”¨AIè§†å›¾è¿›è¡Œè¯¦ç»†åˆ†æ")
                    
                    # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
                    col1, col2, col3 = st.columns(3)
                    col1.metric("æ ·æœ¬é‡", df[var].count())
                    col2.metric("å”¯ä¸€å€¼", df[var].nunique())
                    col3.metric("ç¼ºå¤±å€¼", df[var].isnull().sum())
                    
                    # æ˜¾ç¤ºå‰5ä¸ªæœ€å¸¸è§çš„å€¼ï¼ˆæ·»åŠ å æ¯”ï¼‰
                    if not is_multiple_choice:
                        st.write("æœ€å¸¸è§çš„å€¼ï¼š")
                        value_counts = df[var].value_counts().head(5)
                        percentages = (value_counts / df[var].count() * 100).round(2)
                        
                        # åˆ›å»ºå¸¦å æ¯”çš„æ•°æ®æ¡†
                        freq_df = pd.DataFrame({
                            'å€¼': value_counts.index.astype(str),
                            'é¢‘æ¬¡': value_counts.values,
                            'å æ¯”(%)': [f"{p:.2f}%" for p in percentages.values]
                        })
                        
                        st.dataframe(freq_df, use_container_width=True, hide_index=True)
                    st.markdown("---")
            
            if not numeric_vars and not non_numeric_vars:
                st.warning("âš ï¸ æœªé€‰æ‹©ä»»ä½•å˜é‡")
            st.session_state.stat_result = f"æè¿°ç»Ÿè®¡ç»“æœï¼š{len(vars)} ä¸ªå˜é‡"
            
            # AIæ™ºèƒ½åˆ†æï¼ˆä»…é’ˆå¯¹æ•°å€¼å‹å˜é‡ï¼‰
            if numeric_vars:
                st.markdown("---")
                st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                
                with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                    try:
                        # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦æ–‡æœ¬ï¼ˆä»…æ•°å€¼å‹å˜é‡ï¼‰
                        stats_text = []
                        for var in numeric_vars:
                            # ä½¿ç”¨å·²è½¬æ¢çš„æ•°å€¼æ•°æ®
                            numeric_data = numeric_df[var].dropna()
                            if len(numeric_data) == 0:
                                continue
                            mean = float(numeric_data.mean())
                            std = float(numeric_data.std())
                            min_val = float(numeric_data.min())
                            max_val = float(numeric_data.max())
                            stats_text.append(f"- {var}ï¼šå¹³å‡å€¼={mean:.2f}ï¼Œæ ‡å‡†å·®={std:.2f}ï¼ŒèŒƒå›´=[{min_val:.2f}, {max_val:.2f}]")
                    
                        if stats_text:
                            result_data = {
                                'stats': '\n'.join(stats_text)
                            }
                            
                            ai_analysis = get_ai_analysis(result_data, "descriptive")
                            
                            if ai_analysis:
                                st.info(ai_analysis)
                            else:
                                st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
                        else:
                            st.warning("âš ï¸ æ‰€é€‰å˜é‡ä¸åŒ…å«æœ‰æ•ˆçš„æ•°å€¼æ•°æ®ã€‚")
                    except Exception as e:
                        st.warning(f"âš ï¸ æ— æ³•ç”ŸæˆAIåˆ†æï¼š{str(e)}")
            
            # ä¸ºéæ•°å€¼å‹å˜é‡æä¾›æç¤º
            if non_numeric_vars:
                st.info("ğŸ’¡ **æç¤º**ï¼šæ£€æµ‹åˆ°åˆ†ç±»/æ–‡æœ¬å˜é‡ã€‚å¦‚éœ€å¯¹å¤šé€‰é¢˜è¿›è¡Œè¯¦ç»†åˆ†æï¼Œè¯·å‰å¾€ **ğŸ¤– AI è¾…åŠ©åˆ†æ** è§†å›¾ã€‚")
    
    # åˆ†ç»„æè¿°ç»Ÿè®¡ (index 1)
    elif stat_index == 1:
        subheader = "ğŸ“Š åˆ†ç»„æè¿°ç»Ÿè®¡" if lang == 'zh' else "ğŸ“Š Ğ‘Ò¯Ğ»Ğ³ÑÑÑ€ Ñ‚Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€Ğ»Ğ°Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº"
        st.subheader(subheader)
        
        # é€‰æ‹©åˆ†ç»„å˜é‡
        label = "é€‰æ‹©åˆ†ç»„å˜é‡" if lang == 'zh' else "Ğ‘Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ ÑĞ¾Ğ½Ğ³Ğ¾Ñ…"
        help_text = "æŒ‰æ­¤å˜é‡åˆ†ç»„è®¡ç®—ç»Ÿè®¡é‡ï¼ˆå¦‚ï¼šå¹´çº§ã€æ€§åˆ«ã€å­¦æ ¡ç­‰ï¼‰" if lang == 'zh' else "Ğ­Ğ½Ñ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ğ°Ğ°Ñ€ Ğ±Ò¯Ğ»ÑĞ³Ğ»ÑĞ½ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ… (Ğ¶Ğ¸ÑˆÑÑ: Ğ°Ğ½Ğ³Ğ¸, Ñ…Ò¯Ğ¹Ñ, ÑÑƒÑ€Ğ³ÑƒÑƒĞ»ÑŒ)"
        group_var = st.selectbox(label, df.columns, key="group_desc_var", help=help_text)
        
        # é€‰æ‹©è¦åˆ†æçš„å˜é‡
        label = "é€‰æ‹©è¦åˆ†æçš„å˜é‡" if lang == 'zh' else "Ğ¨Ğ¸Ğ½Ğ¶Ğ»ÑÑ… Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ ÑĞ¾Ğ½Ğ³Ğ¾Ñ…"
        help_text = "å¯ä»¥é€‰æ‹©å¤šä¸ªå˜é‡è¿›è¡Œåˆ†ç»„ç»Ÿè®¡" if lang == 'zh' else "ĞĞ»Ğ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ ÑĞ¾Ğ½Ğ³Ğ¾Ğ¶ Ğ±Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ñ…Ğ¸Ğ¹Ğ¶ Ğ±Ğ¾Ğ»Ğ½Ğ¾"
        vars = st.multiselect(label, df.columns, key="group_desc_vars", help=help_text)
        
        # é«˜çº§é€‰é¡¹ï¼šæ˜¯å¦è®¡ç®—ç»´åº¦å¾—åˆ†
        with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹ï¼šç»´åº¦å¾—åˆ†è®¡ç®—" if lang == 'zh' else "ğŸ”§ ĞÑĞ¼ÑĞ»Ñ‚ ÑĞ¾Ğ½Ğ³Ğ¾Ğ»Ñ‚: Ğ¥ÑĞ¼Ğ¶ÑÑÑĞ¸Ğ¹Ğ½ Ğ¾Ğ½Ğ¾Ğ¾"):
            calc_dimension = st.checkbox(
                "è®¡ç®—ç»´åº¦å¾—åˆ†ï¼ˆå°†é€‰ä¸­çš„å˜é‡å¹³å‡åå†ç»Ÿè®¡ï¼‰" if lang == 'zh' else "Ğ¥ÑĞ¼Ğ¶ÑÑÑĞ¸Ğ¹Ğ½ Ğ¾Ğ½Ğ¾Ğ¾ Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ… (ÑĞ¾Ğ½Ğ³Ğ¾ÑĞ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ğ´Ñ‹Ğ½ Ğ´ÑƒĞ½Ğ´Ğ¶Ğ¸Ğ¹Ğ³ Ğ°Ğ²Ğ½Ğ°)",
                value=False,
                key="calc_dimension",
                help="å‹¾é€‰åï¼Œä¼šå…ˆè®¡ç®—æ¯ä¸ªæ ·æœ¬åœ¨æ‰€é€‰å˜é‡ä¸Šçš„å¹³å‡åˆ†ï¼Œç„¶åæŒ‰ç»„ç»Ÿè®¡" if lang == 'zh' else "Ğ¡Ğ¾Ğ½Ğ³Ğ¾Ğ²Ğ¾Ğ» ÑÑ…Ğ»ÑÑĞ´ ÑĞ¾Ğ½Ğ³Ğ¾ÑĞ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ğ´Ñ‹Ğ½ Ğ´ÑƒĞ½Ğ´Ğ¶Ğ¸Ğ¹Ğ³ Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¶, Ğ´Ğ°Ñ€Ğ°Ğ° Ğ½ÑŒ Ğ±Ò¯Ğ»Ğ³ÑÑÑ€ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ñ…Ğ¸Ğ¹Ğ½Ñ"
            )
        
        btn_text = "è®¡ç®—åˆ†ç»„ç»Ÿè®¡" if lang == 'zh' else "Ğ‘Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ…"
        if vars and st.button(btn_text):
            try:
                # è·å–åˆ†ç»„
                groups = sorted(df[group_var].dropna().unique())
                
                if len(groups) < 2:
                    warning_text = "âš ï¸ åˆ†ç»„å˜é‡è‡³å°‘éœ€è¦2ä¸ªä¸åŒçš„å€¼" if lang == 'zh' else "âš ï¸ Ğ‘Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ Ñ…Ğ°Ğ¼Ğ³Ğ¸Ğ¹Ğ½ Ğ±Ğ°Ğ³Ğ°Ğ´Ğ°Ğ° 2 Ó©Ó©Ñ€ ÑƒÑ‚Ğ³Ğ°Ñ‚Ğ°Ğ¹ Ğ±Ğ°Ğ¹Ñ… Ñ‘ÑÑ‚Ğ¾Ğ¹"
                    st.warning(warning_text)
                else:
                    # å‡†å¤‡ç»“æœæ•°æ®
                    results = []
                    
                    for group in groups:
                        group_data = df[df[group_var] == group]
                        row = {group_var: str(group), 'æ ·æœ¬é‡' if lang == 'zh' else 'Ğ¢Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ Ñ‚Ğ¾Ğ¾': len(group_data)}
                        
                        if calc_dimension:
                            # è®¡ç®—ç»´åº¦å¾—åˆ†æ¨¡å¼ï¼šå…ˆè®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¹³å‡åˆ†
                            dimension_scores = group_data[vars].apply(pd.to_numeric, errors='coerce').mean(axis=1)
                            
                            row['å‡å€¼' if lang == 'zh' else 'Ğ”ÑƒĞ½Ğ´Ğ°Ğ¶'] = round(float(dimension_scores.mean()), 2)
                            row['æ ‡å‡†å·®' if lang == 'zh' else 'Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ñ…Ğ°Ğ·Ğ°Ğ¹Ğ»Ñ‚'] = round(float(dimension_scores.std()), 2)
                            row['æœ€å°å€¼' if lang == 'zh' else 'Ğ¥Ğ°Ğ¼Ğ³Ğ¸Ğ¹Ğ½ Ğ±Ğ°Ğ³Ğ°'] = round(float(dimension_scores.min()), 2)
                            row['æœ€å¤§å€¼' if lang == 'zh' else 'Ğ¥Ğ°Ğ¼Ğ³Ğ¸Ğ¹Ğ½ Ğ¸Ñ…'] = round(float(dimension_scores.max()), 2)
                        else:
                            # æ™®é€šæ¨¡å¼ï¼šåˆ†åˆ«ç»Ÿè®¡æ¯ä¸ªå˜é‡
                            for var in vars:
                                var_data = pd.to_numeric(group_data[var], errors='coerce').dropna()
                                
                                if len(var_data) > 0:
                                    row[f'{var}_å‡å€¼' if lang == 'zh' else f'{var}_Ğ”ÑƒĞ½Ğ´Ğ°Ğ¶'] = round(float(var_data.mean()), 2)
                                    row[f'{var}_æ ‡å‡†å·®' if lang == 'zh' else f'{var}_Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚'] = round(float(var_data.std()), 2)
                                else:
                                    row[f'{var}_å‡å€¼' if lang == 'zh' else f'{var}_Ğ”ÑƒĞ½Ğ´Ğ°Ğ¶'] = np.nan
                                    row[f'{var}_æ ‡å‡†å·®' if lang == 'zh' else f'{var}_Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚'] = np.nan
                        
                        results.append(row)
                    
                    # åˆ›å»ºç»“æœDataFrame
                    result_df = pd.DataFrame(results)
                    
                    # æ˜¾ç¤ºç»“æœ
                    if calc_dimension:
                        title = f"#### ğŸ“Š ç»´åº¦å¾—åˆ†åˆ†ç»„ç»Ÿè®¡ï¼ˆå˜é‡ï¼š{', '.join(vars)}ï¼‰" if lang == 'zh' else f"#### ğŸ“Š Ğ¥ÑĞ¼Ğ¶ÑÑÑĞ¸Ğ¹Ğ½ Ğ¾Ğ½Ğ¾Ğ¾ Ğ±Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğºï¼ˆĞ¥ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ï¼š{', '.join(vars)}ï¼‰"
                    else:
                        title = "#### ğŸ“Š åˆ†ç»„æè¿°ç»Ÿè®¡ç»“æœ" if lang == 'zh' else "#### ğŸ“Š Ğ‘Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ Ñ‚Ğ°Ğ¹Ğ»Ğ±Ğ°Ñ€Ğ»Ğ°Ñ… ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸Ğ¹Ğ½ Ò¯Ñ€ Ğ´Ò¯Ğ½"
                    
                    st.markdown(title)
                    st.dataframe(result_df, use_container_width=True, hide_index=True)
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.stat_result = f"åˆ†ç»„æè¿°ç»Ÿè®¡ï¼šæŒ‰ {group_var} åˆ†ç»„ï¼Œ{len(vars)} ä¸ªå˜é‡"
                    
                    # æä¾›ä¸‹è½½é€‰é¡¹
                    st.markdown("---")
                    col_download1, col_download2 = st.columns(2)
                    
                    with col_download1:
                        # å¯¼å‡ºä¸ºCSV
                        csv = result_df.to_csv(index=False, encoding='utf-8-sig')
                        download_label = "ğŸ“¥ ä¸‹è½½ CSV" if lang == 'zh' else "ğŸ“¥ CSV Ñ‚Ğ°Ñ‚Ğ°Ñ…"
                        st.download_button(
                            label=download_label,
                            data=csv,
                            file_name=f"åˆ†ç»„ç»Ÿè®¡_{group_var}.csv",
                            mime="text/csv",
                            use_container_width=True
                        )
                    
                    with col_download2:
                        # å¯¼å‡ºä¸ºExcel
                        import io
                        buffer = io.BytesIO()
                        result_df.to_excel(buffer, index=False, engine='openpyxl')
                        download_label = "ğŸ“¥ ä¸‹è½½ Excel" if lang == 'zh' else "ğŸ“¥ Excel Ñ‚Ğ°Ñ‚Ğ°Ñ…"
                        st.download_button(
                            label=download_label,
                            data=buffer.getvalue(),
                            file_name=f"åˆ†ç»„ç»Ÿè®¡_{group_var}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        try:
                            # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦æ–‡æœ¬
                            stats_text = []
                            for idx, row in result_df.iterrows():
                                group_name = row[group_var]
                                sample_size = row['æ ·æœ¬é‡' if lang == 'zh' else 'Ğ¢Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ Ñ‚Ğ¾Ğ¾']
                                
                                if calc_dimension:
                                    mean_val = row['å‡å€¼' if lang == 'zh' else 'Ğ”ÑƒĞ½Ğ´Ğ°Ğ¶']
                                    std_val = row['æ ‡å‡†å·®' if lang == 'zh' else 'Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ñ…Ğ°Ğ·Ğ°Ğ¹Ğ»Ñ‚']
                                    stats_text.append(f"- {group_name}ç»„ï¼šæ ·æœ¬é‡={sample_size}ï¼Œå‡å€¼={mean_val:.2f}ï¼Œæ ‡å‡†å·®={std_val:.2f}")
                                else:
                                    # æ™®é€šæ¨¡å¼ï¼šåˆ—å‡ºæ¯ä¸ªå˜é‡çš„ç»Ÿè®¡
                                    var_stats = []
                                    for var in vars:
                                        mean_col = f'{var}_å‡å€¼' if lang == 'zh' else f'{var}_Ğ”ÑƒĞ½Ğ´Ğ°Ğ¶'
                                        std_col = f'{var}_æ ‡å‡†å·®' if lang == 'zh' else f'{var}_Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚'
                                        if mean_col in row and not pd.isna(row[mean_col]):
                                            var_stats.append(f"{var}(å‡å€¼={row[mean_col]:.2f}, æ ‡å‡†å·®={row[std_col]:.2f})")
                                    if var_stats:
                                        stats_text.append(f"- {group_name}ç»„ï¼šæ ·æœ¬é‡={sample_size}ï¼Œ{', '.join(var_stats)}")
                            
                            if stats_text:
                                result_data = {
                                    'stats': '\n'.join(stats_text)
                                }
                                
                                ai_analysis = get_ai_analysis(result_data, "descriptive")
                                
                                if ai_analysis:
                                    st.info(ai_analysis)
                                else:
                                    st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
                        except Exception as e:
                            st.warning(f"âš ï¸ æ— æ³•ç”ŸæˆAIåˆ†æï¼š{str(e)}")
                    
                    # ä½¿ç”¨è¯´æ˜
                    st.markdown("---")
                    st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœéœ€è¦ç”Ÿæˆå¤šä¸ªç»´åº¦çš„åˆ†ç»„ç»Ÿè®¡è¡¨ï¼Œå¯ä»¥å¤šæ¬¡è¿è¡Œæ­¤åˆ†æï¼Œæ¯æ¬¡é€‰æ‹©ä¸åŒçš„å˜é‡ç»„åˆã€‚" if lang == 'zh' else "ğŸ’¡ Ğ—Ó©Ğ²Ğ»Ó©Ğ¼Ğ¶: ĞĞ»Ğ¾Ğ½ Ñ…ÑĞ¼Ğ¶ÑÑÑĞ¸Ğ¹Ğ½ Ğ±Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ğº Ò¯Ò¯ÑĞ³ÑÑ… ÑˆĞ°Ğ°Ñ€Ğ´Ğ»Ğ°Ğ³Ğ°Ñ‚Ğ°Ğ¹ Ğ±Ğ¾Ğ» ÑĞ½Ñ ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑĞ³ Ğ¾Ğ»Ğ¾Ğ½ ÑƒĞ´Ğ°Ğ° Ğ°Ğ¶Ğ¸Ğ»Ğ»ÑƒÑƒĞ»Ğ¶, Ó©Ó©Ñ€ Ó©Ó©Ñ€ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ğ´Ñ‹Ğ½ Ñ…Ğ¾ÑĞ»Ğ¾Ğ»Ñ‹Ğ³ ÑĞ¾Ğ½Ğ³Ğ¾Ğ½Ğ¾ ÑƒÑƒ.")
                    
            except Exception as e:
                error_text = f"âŒ è®¡ç®—å¤±è´¥ï¼š{str(e)}" if lang == 'zh' else f"âŒ Ğ¢Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ… Ğ°Ğ¼Ğ¶Ğ¸Ğ»Ñ‚Ğ³Ò¯Ğ¹ï¼š{str(e)}"
                st.error(error_text)
    
    # å•æ ·æœ¬ t æ£€éªŒ (index 2)
    elif stat_index == 2:
        subheader = "ğŸ”¬ å•æ ·æœ¬ t æ£€éªŒ" if lang == 'zh' else "ğŸ”¬ ĞÑĞ³ Ñ‚Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ t ÑˆĞ°Ğ»Ğ³Ğ°Ğ»Ñ‚"
        st.subheader(subheader)
        
        label = "é€‰æ‹©å˜é‡" if lang == 'zh' else "Ğ¥ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ ÑĞ¾Ğ½Ğ³Ğ¾Ñ…"
        var = st.selectbox(label, df.columns, key="t1_var")
        label = "æ£€éªŒå€¼ (Î¼â‚€)" if lang == 'zh' else "Ğ¨Ğ°Ğ»Ğ³Ğ°Ñ… ÑƒÑ‚Ğ³Ğ° (Î¼â‚€)"
        mu = st.number_input(label, value=0.0, key="t1_mu")
        
        btn = "æ‰§è¡Œæ£€éªŒ" if lang == 'zh' else "Ğ¨Ğ°Ğ»Ğ³Ğ°Ğ»Ñ‚ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                data = pd.to_numeric(df[var], errors='coerce').dropna()
                
                if len(data) < 2:
                    st.error("âŒ æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•æ‰§è¡Œtæ£€éªŒï¼ˆè‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    t_stat, p_value = stats.ttest_1samp(data, mu)
                    
                    result_df = pd.DataFrame({
                        'å˜é‡': [var],
                        'æ ·æœ¬é‡': [len(data)],
                        'å‡å€¼': [float(data.mean())],
                        'æ ‡å‡†å·®': [float(data.std())],
                        'æ£€éªŒå€¼': [mu],
                        't ç»Ÿè®¡é‡': [float(t_stat)],
                        'p å€¼': [float(p_value)],
                        'æ˜¾è‘—æ€§': ['***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns']
                    })
                    
                    st.dataframe(result_df, use_container_width=True)
                    st.session_state.stat_result = f"å•æ ·æœ¬ t æ£€éªŒï¼š{var} vs {mu}, p={p_value:.4f}"
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        result_data = {
                            'variable': var,
                            'mean': float(data.mean()),
                            'test_value': mu,
                            't': float(t_stat),
                            'p': float(p_value)
                        }
                        
                        ai_analysis = get_ai_analysis(result_data, "one_sample_t")
                        
                        if ai_analysis:
                            if p_value < 0.05:
                                st.success(ai_analysis)
                            else:
                                st.info(ai_analysis)
                        else:
                            st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œæ£€éªŒæ—¶å‡ºé”™ï¼š{str(e)}")
    
    # é…å¯¹æ ·æœ¬ t æ£€éªŒ (index 3)
    elif stat_index == 3:
        subheader = "ğŸ‘¥ é…å¯¹æ ·æœ¬ t æ£€éªŒ" if lang == 'zh' else "ğŸ‘¥ Ğ¥Ğ¾ÑĞ»Ğ¾ÑĞ¾Ğ½ Ñ‚Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ t ÑˆĞ°Ğ»Ğ³Ğ°Ğ»Ñ‚"
        st.subheader(subheader)
        
        label1 = "å˜é‡ 1" if lang == 'zh' else "Ğ¥ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ 1"
        var1 = st.selectbox(label1, df.columns, key="t2_var1")
        label2 = "å˜é‡ 2" if lang == 'zh' else "Ğ¥ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ 2"
        var2 = st.selectbox(label2, df.columns, key="t2_var2")
        
        btn = "æ‰§è¡Œæ£€éªŒ" if lang == 'zh' else "Ğ¨Ğ°Ğ»Ğ³Ğ°Ğ»Ñ‚ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                data1 = pd.to_numeric(df[var1], errors='coerce').dropna()
                data2 = pd.to_numeric(df[var2], errors='coerce').dropna()
                
                if len(data1) < 2 or len(data2) < 2:
                    st.error("âŒ æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•æ‰§è¡Œtæ£€éªŒï¼ˆè‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    # ä¿è¯é…å¯¹ - ä½¿ç”¨å…±åŒçš„ç´¢å¼•
                    common_idx = data1.index.intersection(data2.index)
                    data1_paired = data1.loc[common_idx]
                    data2_paired = data2.loc[common_idx]
                    
                    if len(data1_paired) < 2:
                        st.error("âŒ é…å¯¹æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•æ‰§è¡Œé…å¯¹tæ£€éªŒï¼ˆè‡³å°‘éœ€è¦2å¯¹æœ‰æ•ˆæ•°æ®ï¼‰")
                    else:
                        t_stat, p_value = stats.ttest_rel(data1_paired, data2_paired)
                        
                        result_df = pd.DataFrame({
                            'å˜é‡1': [var1],
                            'å˜é‡2': [var2],
                            'æ ·æœ¬é‡': [len(data1_paired)],
                            'å‡å€¼å·®': [float(data1_paired.mean() - data2_paired.mean())],
                            't ç»Ÿè®¡é‡': [float(t_stat)],
                            'p å€¼': [float(p_value)],
                            'æ˜¾è‘—æ€§': ['***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns']
                        })
                        
                        st.dataframe(result_df, use_container_width=True)
                        st.session_state.stat_result = f"é…å¯¹ t æ£€éªŒï¼š{var1} vs {var2}, p={p_value:.4f}"
                        
                        # AIæ™ºèƒ½åˆ†æ
                        st.markdown("---")
                        st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                        
                        with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                            result_data = {
                                'var1': var1,
                                'var2': var2,
                                'mean1': float(data1_paired.mean()),
                                'mean2': float(data2_paired.mean()),
                                'mean_diff': float(data1_paired.mean() - data2_paired.mean()),
                                't': float(t_stat),
                                'p': float(p_value)
                            }
                            
                            ai_analysis = get_ai_analysis(result_data, "paired_t")
                            
                            if ai_analysis:
                                if p_value < 0.05:
                                    st.success(ai_analysis)
                                else:
                                    st.info(ai_analysis)
                            else:
                                st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œæ£€éªŒæ—¶å‡ºé”™ï¼š{str(e)}")
    
    # ç‹¬ç«‹æ ·æœ¬ t æ£€éªŒ (index 4)
    elif stat_index == 4:
        subheader = "ğŸ”€ ç‹¬ç«‹æ ·æœ¬ t æ£€éªŒ" if lang == 'zh' else "ğŸ”€ Ğ‘Ğ¸Ğµ Ğ´Ğ°Ğ°ÑĞ°Ğ½ Ñ‚Ò¯Ò¯Ğ²Ñ€Ğ¸Ğ¹Ğ½ t ÑˆĞ°Ğ»Ğ³Ğ°Ğ»Ñ‚"
        st.subheader(subheader)
        
        label = "æ•°æ®å˜é‡" if lang == 'zh' else "Ó¨Ğ³Ó©Ğ³Ğ´Ğ»Ğ¸Ğ¹Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡"
        data_var = st.selectbox(label, df.columns, key="t3_data")
        label = "åˆ†ç»„å˜é‡" if lang == 'zh' else "Ğ‘Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡"
        group_var = st.selectbox(label, df.columns, key="t3_group")
        
        btn = "æ‰§è¡Œæ£€éªŒ" if lang == 'zh' else "Ğ¨Ğ°Ğ»Ğ³Ğ°Ğ»Ñ‚ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if st.button(btn):
            try:
                groups = df[group_var].unique()
                if len(groups) != 2:
                    st.error("âŒ åˆ†ç»„å˜é‡å¿…é¡»æ°å¥½æœ‰ 2 ä¸ªæ°´å¹³")
                else:
                    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    group1 = pd.to_numeric(df[df[group_var] == groups[0]][data_var], errors='coerce').dropna()
                    group2 = pd.to_numeric(df[df[group_var] == groups[1]][data_var], errors='coerce').dropna()
                    
                    if len(group1) < 2 or len(group2) < 2:
                        st.error("âŒ æ¯ç»„è‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹")
                    else:
                        t_stat, p_value = stats.ttest_ind(group1, group2)
                        
                        result_df = pd.DataFrame({
                            'åˆ†ç»„å˜é‡': [group_var],
                            'ç»„1': [groups[0]],
                            'ç»„2': [groups[1]],
                            'n1': [len(group1)],
                            'n2': [len(group2)],
                            'M1': [float(group1.mean())],
                            'M2': [float(group2.mean())],
                            't ç»Ÿè®¡é‡': [float(t_stat)],
                            'p å€¼': [float(p_value)],
                            'æ˜¾è‘—æ€§': ['***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns']
                        })
                        
                        st.dataframe(result_df, use_container_width=True)
                        st.session_state.stat_result = f"ç‹¬ç«‹ t æ£€éªŒï¼š{data_var} by {group_var}, p={p_value:.4f}"
                        
                        # AIæ™ºèƒ½åˆ†æ
                        st.markdown("---")
                        st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                        
                        with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                            result_data = {
                                'group_var': group_var,
                                'data_var': data_var,
                                'group1': str(groups[0]),
                                'group2': str(groups[1]),
                                'mean1': float(group1.mean()),
                                'mean2': float(group2.mean()),
                                't': float(t_stat),
                                'p': float(p_value)
                            }
                            
                            ai_analysis = get_ai_analysis(result_data, "t_test")
                            
                            if ai_analysis:
                                if p_value < 0.05:
                                    st.success(ai_analysis)
                                else:
                                    st.info(ai_analysis)
                            else:
                                # å¦‚æœAIåˆ†æå¤±è´¥ï¼Œæ˜¾ç¤ºç®€å•æç¤º
                                st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œæ£€éªŒæ—¶å‡ºé”™ï¼š{str(e)}")
    
    # å•å› ç´ æ–¹å·®åˆ†æ (index 5)
    elif stat_index == 5:
        subheader = "ğŸ“ å•å› ç´ æ–¹å·®åˆ†æ (ANOVA)" if lang == 'zh' else "ğŸ“ ĞÑĞ³ Ñ…Ò¯Ñ‡Ğ¸Ğ½ Ğ·Ò¯Ğ¹Ğ»Ğ¸Ğ¹Ğ½ ANOVA"
        st.subheader(subheader)
        
        label = "å› å˜é‡" if lang == 'zh' else "Ğ¥Ğ°Ğ¼Ğ°Ğ°Ñ€Ğ°Ğ»Ñ‚Ğ°Ğ¹ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡"
        data_var = st.selectbox(label, df.columns, key="anova_data")
        label = "å› ç´ ï¼ˆåˆ†ç»„å˜é‡ï¼‰" if lang == 'zh' else "Ğ¥Ò¯Ñ‡Ğ¸Ğ½ Ğ·Ò¯Ğ¹Ğ» (Ğ±Ò¯Ğ»Ğ³Ğ¸Ğ¹Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡)"
        group_var = st.selectbox(label, df.columns, key="anova_group")
        
        btn = "æ‰§è¡Œåˆ†æ" if lang == 'zh' else "Ğ¨Ğ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if st.button(btn):
            try:
                groups = df[group_var].unique()
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                group_data = [pd.to_numeric(df[df[group_var] == g][data_var], errors='coerce').dropna() for g in groups]
                
                # æ£€æŸ¥æ¯ç»„è‡³å°‘æœ‰æ•°æ®
                valid_groups = [g for g in group_data if len(g) >= 1]
                if len(valid_groups) < 2:
                    st.error("âŒ è‡³å°‘éœ€è¦2ç»„æœ‰æ•ˆæ•°æ®æ‰èƒ½è¿›è¡Œæ–¹å·®åˆ†æ")
                else:
                    f_stat, p_value = f_oneway(*valid_groups)
                    
                    result_df = pd.DataFrame({
                        'å› å˜é‡': [data_var],
                        'å› ç´ ': [group_var],
                        'ç»„æ•°': [len(valid_groups)],
                        'F ç»Ÿè®¡é‡': [float(f_stat)],
                        'p å€¼': [float(p_value)],
                        'æ˜¾è‘—æ€§': ['***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'ns']
                    })
                    
                    st.dataframe(result_df, use_container_width=True)
                    
                    # æ–¹å·®é½æ€§æ£€éªŒ
                    lev_stat, lev_p = levene(*valid_groups)
                    st.info(f"ğŸ“Š Levene æ–¹å·®é½æ€§æ£€éªŒï¼šF={lev_stat:.4f}, p={lev_p:.4f}")
                    
                    st.session_state.stat_result = f"å•å› ç´  ANOVAï¼š{data_var} by {group_var}, F={f_stat:.4f}, p={p_value:.4f}"
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        result_data = {
                            'dependent': data_var,
                            'factor': group_var,
                            'n_groups': len(valid_groups),
                            'f': float(f_stat),
                            'p': float(p_value)
                        }
                        
                        ai_analysis = get_ai_analysis(result_data, "anova")
                        
                        if ai_analysis:
                            if p_value < 0.05:
                                st.success(ai_analysis)
                            else:
                                st.info(ai_analysis)
                        else:
                            st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œåˆ†ææ—¶å‡ºé”™ï¼š{str(e)}")
    
    # Pearson ç›¸å…³åˆ†æ (index 6)
    elif stat_index == 6:
        subheader = "ğŸ”— Pearson ç›¸å…³åˆ†æ" if lang == 'zh' else "ğŸ”— Pearson ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¹Ğ½ ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ"
        st.subheader(subheader)
        
        label = "é€‰æ‹©å˜é‡ï¼ˆè‡³å°‘2ä¸ªï¼‰" if lang == 'zh' else "Ğ¥ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ ÑĞ¾Ğ½Ğ³Ğ¾Ñ… (Ñ…Ğ°Ğ¼Ğ³Ğ¸Ğ¹Ğ½ Ğ±Ğ°Ğ³Ğ°Ğ´Ğ°Ğ° 2)"
        vars = st.multiselect(label, df.columns, key="corr_vars")
        
        btn = "è®¡ç®—ç›¸å…³" if lang == 'zh' else "ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸ Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ…"
        if len(vars) >= 2 and st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                numeric_df = df[vars].apply(pd.to_numeric, errors='coerce')
                numeric_df = numeric_df.dropna()
                
                if len(numeric_df) < 3:
                    st.error("âŒ æœ‰æ•ˆæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œç›¸å…³åˆ†æï¼ˆè‡³å°‘éœ€è¦3ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    corr_matrix = numeric_df.corr()
                    
                    st.write("#### ç›¸å…³ç³»æ•°çŸ©é˜µ")
                    st.dataframe(corr_matrix.style.background_gradient(cmap='coolwarm', vmin=-1, vmax=1), use_container_width=True)
                    
                    # æ˜¾è‘—æ€§æ£€éªŒ
                    st.write("#### æ˜¾è‘—æ€§æ£€éªŒ")
                    n = len(numeric_df)
                    p_matrix = pd.DataFrame(index=vars, columns=vars)
                    
                    for i, var1 in enumerate(vars):
                        for j, var2 in enumerate(vars):
                            if i != j:
                                r = float(corr_matrix.loc[var1, var2])
                                # é˜²æ­¢é™¤é›¶é”™è¯¯ï¼šå½“ræ¥è¿‘Â±1æ—¶ï¼Œ1-rÂ²æ¥è¿‘0
                                if abs(r) >= 0.9999:
                                    # å®Œå…¨ç›¸å…³æˆ–å®Œå…¨è´Ÿç›¸å…³ï¼Œpå€¼æå°
                                    p_matrix.loc[var1, var2] = 0.0
                                else:
                                    t = r * np.sqrt(n - 2) / np.sqrt(1 - r**2)
                                    p = 2 * (1 - stats.t.cdf(abs(t), n - 2))
                                    p_matrix.loc[var1, var2] = p
                            else:
                                p_matrix.loc[var1, var2] = 1.0
                    
                    st.dataframe(p_matrix.astype(float).style.format("{:.4f}"), use_container_width=True)
                    st.session_state.stat_result = f"Pearson ç›¸å…³ï¼š{len(vars)} ä¸ªå˜é‡"
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        # å‡†å¤‡æ‰€æœ‰å˜é‡å¯¹çš„æ•°æ®
                        pairs_info = []
                        for i, var1 in enumerate(vars):
                            for j, var2 in enumerate(vars):
                                if i < j:  # é¿å…é‡å¤
                                    r = float(corr_matrix.loc[var1, var2])
                                    p = float(p_matrix.loc[var1, var2])
                                    pairs_info.append(f"- {var1} ä¸ {var2}ï¼šr={r:.3f}, p={p:.4f}")
                        
                        result_data = {
                            'pairs': '\n'.join(pairs_info)
                        }
                        
                        ai_analysis = get_ai_analysis(result_data, "correlation")
                        
                        if ai_analysis:
                            st.success(ai_analysis)
                        else:
                            st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œåˆ†ææ—¶å‡ºé”™ï¼š{str(e)}")
    
    # ä¸€å…ƒçº¿æ€§å›å½’ (index 7)
    elif stat_index == 7:
        subheader = "ğŸ“ˆ ä¸€å…ƒçº¿æ€§å›å½’" if lang == 'zh' else "ğŸ“ˆ ĞÑĞ³ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ñ‚Ğ°Ğ¹ ÑˆÑƒĞ³Ğ°Ğ¼Ğ°Ğ½ Ñ€ĞµĞ³Ñ€ĞµÑÑ"
        st.subheader(subheader)
        
        label = "è‡ªå˜é‡ (X)" if lang == 'zh' else "Ğ‘Ğ¸Ğµ Ğ´Ğ°Ğ°ÑĞ°Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (X)"
        x_var = st.selectbox(label, df.columns, key="reg1_x")
        label = "å› å˜é‡ (Y)" if lang == 'zh' else "Ğ¥Ğ°Ğ¼Ğ°Ğ°Ñ€Ğ°Ğ»Ñ‚Ğ°Ğ¹ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (Y)"
        y_var = st.selectbox(label, df.columns, key="reg1_y")
        
        btn = "æ‰§è¡Œå›å½’" if lang == 'zh' else "Ğ ĞµĞ³Ñ€ĞµÑÑ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                data = df[[x_var, y_var]].apply(pd.to_numeric, errors='coerce').dropna()
                
                if len(data) < 3:
                    st.error("âŒ æœ‰æ•ˆæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œå›å½’åˆ†æï¼ˆè‡³å°‘éœ€è¦3ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    X = sm.add_constant(data[x_var])
                    y = data[y_var]
                    
                    model = sm.OLS(y, X).fit()
                    
                    st.write("#### å›å½’æ‘˜è¦")
                    st.text(model.summary())
                    
                    st.write("#### å›å½’æ–¹ç¨‹")
                    st.latex(f"Y = {model.params[1]:.4f} \\times X + {model.params[0]:.4f}")
                    st.info(f"RÂ² = {model.rsquared:.4f}, p = {model.f_pvalue:.4f}")
                    
                    st.session_state.stat_result = f"ä¸€å…ƒå›å½’ï¼š{y_var} ~ {x_var}, RÂ²={model.rsquared:.4f}"
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        result_data = {
                            'predictors': x_var,
                            'outcome': y_var,
                            'r2': float(model.rsquared),
                            'p': float(model.f_pvalue)
                        }
                        
                        ai_analysis = get_ai_analysis(result_data, "regression")
                        
                        if ai_analysis:
                            if model.f_pvalue < 0.05:
                                st.success(ai_analysis)
                            else:
                                st.info(ai_analysis)
                        else:
                            st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œå›å½’æ—¶å‡ºé”™ï¼š{str(e)}")
    
    # å¤šå…ƒçº¿æ€§å›å½’ (index 8)
    elif stat_index == 8:
        subheader = "ğŸ“Š å¤šå…ƒçº¿æ€§å›å½’" if lang == 'zh' else "ğŸ“Š ĞĞ»Ğ¾Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡Ñ‚Ğ°Ğ¹ ÑˆÑƒĞ³Ğ°Ğ¼Ğ°Ğ½ Ñ€ĞµĞ³Ñ€ĞµÑÑ"
        st.subheader(subheader)
        
        label = "å› å˜é‡ (Y)" if lang == 'zh' else "Ğ¥Ğ°Ğ¼Ğ°Ğ°Ñ€Ğ°Ğ»Ñ‚Ğ°Ğ¹ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (Y)"
        y_var = st.selectbox(label, df.columns, key="regm_y")
        label = "è‡ªå˜é‡ (X, å¯å¤šé€‰)" if lang == 'zh' else "Ğ‘Ğ¸Ğµ Ğ´Ğ°Ğ°ÑĞ°Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (X, Ğ¾Ğ»Ğ¾Ğ½ ÑĞ¾Ğ½Ğ³Ğ¾Ğ»Ñ‚Ñ‚Ğ°Ğ¹)"
        x_vars = st.multiselect(label, [c for c in df.columns if c != y_var], key="regm_x")
        
        btn = "æ‰§è¡Œå›å½’" if lang == 'zh' else "Ğ ĞµĞ³Ñ€ĞµÑÑ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if x_vars and st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                data = df[[y_var] + x_vars].apply(pd.to_numeric, errors='coerce').dropna()
                
                if len(data) < len(x_vars) + 2:
                    st.error(f"âŒ æœ‰æ•ˆæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œå›å½’åˆ†æï¼ˆè‡³å°‘éœ€è¦{len(x_vars) + 2}ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    X = sm.add_constant(data[x_vars])
                    y = data[y_var]
                    
                    model = sm.OLS(y, X).fit()
                    
                    st.write("#### å›å½’æ‘˜è¦")
                    st.text(model.summary())
                    
                    st.info(f"RÂ² = {model.rsquared:.4f}, Adj RÂ² = {model.rsquared_adj:.4f}, p = {model.f_pvalue:.4f}")
                    
                    st.session_state.stat_result = f"å¤šå…ƒå›å½’ï¼š{y_var} ~ {'+'.join(x_vars)}, RÂ²={model.rsquared:.4f}"
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        result_data = {
                            'predictors': '+'.join(x_vars),
                            'outcome': y_var,
                            'r2': float(model.rsquared),
                            'p': float(model.f_pvalue)
                        }
                        
                        ai_analysis = get_ai_analysis(result_data, "regression")
                        
                        if ai_analysis:
                            if model.f_pvalue < 0.05:
                                st.success(ai_analysis)
                            else:
                                st.info(ai_analysis)
                        else:
                            st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œå›å½’æ—¶å‡ºé”™ï¼š{str(e)}")
    
    # Cronbach's Alpha ä¿¡åº¦ (index 9)
    elif stat_index == 9:
        subheader = "ğŸ¯ Cronbach's Alpha ä¿¡åº¦åˆ†æ" if lang == 'zh' else "ğŸ¯ Cronbach's Alpha Ğ½Ğ°Ğ¹Ğ´Ğ²Ğ°Ñ€Ñ‚Ğ°Ğ¹ Ğ±Ğ°Ğ¹Ğ´Ğ»Ñ‹Ğ½ ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ"
        st.subheader(subheader)
        
        label = "é€‰æ‹©é¢˜ç›®/é‡è¡¨é¡¹" if lang == 'zh' else "ĞÑÑƒÑƒĞ»Ñ‚/Ñ…ÑĞ¼Ğ¶Ò¯Ò¯Ñ€Ğ¸Ğ¹Ğ½ Ğ·Ò¯Ğ¹Ğ» ÑĞ¾Ğ½Ğ³Ğ¾Ñ…"
        items = st.multiselect(label, df.columns, key="alpha_items")
        
        btn = "è®¡ç®—ä¿¡åº¦" if lang == 'zh' else "ĞĞ°Ğ¹Ğ´Ğ²Ğ°Ñ€Ñ‚Ğ°Ğ¹ Ğ±Ğ°Ğ¹Ğ´Ğ»Ñ‹Ğ³ Ñ‚Ğ¾Ğ¾Ñ†Ğ¾Ğ¾Ğ»Ğ¾Ñ…"
        if len(items) >= 2 and st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                data = df[items].apply(pd.to_numeric, errors='coerce').dropna()
                
                if len(data) < 2:
                    st.error("âŒ æœ‰æ•ˆæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è®¡ç®—ä¿¡åº¦ï¼ˆè‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    n_items = len(items)
                    
                    # è®¡ç®— Cronbach's Alpha
                    item_vars = float(data.var(axis=0).sum())
                    total_var = float(data.sum(axis=1).var())
                    
                    if total_var == 0:
                        st.error("âŒ æ•°æ®æ–¹å·®ä¸º0ï¼Œæ— æ³•è®¡ç®—ä¿¡åº¦")
                    else:
                        alpha = float((n_items / (n_items - 1)) * (1 - item_vars / total_var))
                        
                        result_df = pd.DataFrame({
                            'é¢˜ç›®æ•°': [n_items],
                            'æ ·æœ¬é‡': [len(data)],
                            "Cronbach's Alpha": [alpha]
                        })
                        
                        st.dataframe(result_df, use_container_width=True)
                        
                        if alpha >= 0.9:
                            st.success("âœ… ä¼˜ç§€ä¿¡åº¦ (Î± â‰¥ 0.9)")
                        elif alpha >= 0.8:
                            st.success("âœ… è‰¯å¥½ä¿¡åº¦ (Î± â‰¥ 0.8)")
                        elif alpha >= 0.7:
                            st.info("â„¹ï¸ å¯æ¥å—ä¿¡åº¦ (Î± â‰¥ 0.7)")
                        else:
                            st.warning("âš ï¸ ä¿¡åº¦åä½ (Î± < 0.7)")
                        
                        st.session_state.stat_result = f"Cronbach's Alpha = {alpha:.4f}"
                        
                        # AIæ™ºèƒ½åˆ†æ
                        st.markdown("---")
                        st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                        
                        with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                            result_data = {
                                'n_items': n_items,
                                'alpha': alpha
                            }
                            
                            ai_analysis = get_ai_analysis(result_data, "reliability")
                            
                            if ai_analysis:
                                if alpha >= 0.7:
                                    st.success(ai_analysis)
                                else:
                                    st.warning(ai_analysis)
                            else:
                                st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ è®¡ç®—ä¿¡åº¦æ—¶å‡ºé”™ï¼š{str(e)}")
    
    # ç®€å•ä¸­ä»‹æ•ˆåº” (index 10)
    elif stat_index == 10:
        subheader = "ğŸ”„ ç®€å•ä¸­ä»‹æ•ˆåº”åˆ†æ" if lang == 'zh' else "ğŸ”„ Ğ­Ğ½Ğ³Ğ¸Ğ¹Ğ½ Ğ·ÑƒÑƒÑ‡Ğ»Ğ°Ñ… Ğ½Ó©Ğ»Ó©Ó©Ğ½Ğ¸Ğ¹ ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ"
        st.subheader(subheader)
        
        model_text = "æ¨¡å‹ï¼šX â†’ M â†’ Y" if lang == 'zh' else "Ğ—Ğ°Ğ³Ğ²Ğ°Ñ€ï¼šX â†’ M â†’ Y"
        st.markdown(model_text)
        
        label = "è‡ªå˜é‡ (X)" if lang == 'zh' else "Ğ‘Ğ¸Ğµ Ğ´Ğ°Ğ°ÑĞ°Ğ½ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (X)"
        x_var = st.selectbox(label, df.columns, key="med_x")
        label = "ä¸­ä»‹å˜é‡ (M)" if lang == 'zh' else "Ğ—ÑƒÑƒÑ‡Ğ»Ğ°Ğ³Ñ‡ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (M)"
        m_var = st.selectbox(label, df.columns, key="med_m")
        label = "å› å˜é‡ (Y)" if lang == 'zh' else "Ğ¥Ğ°Ğ¼Ğ°Ğ°Ñ€Ğ°Ğ»Ñ‚Ğ°Ğ¹ Ñ…ÑƒĞ²ÑŒÑĞ°Ğ³Ñ‡ (Y)"
        y_var = st.selectbox(label, df.columns, key="med_y")
        
        btn = "æ‰§è¡Œä¸­ä»‹åˆ†æ" if lang == 'zh' else "Ğ—ÑƒÑƒÑ‡Ğ»Ğ°Ñ… ÑˆĞ¸Ğ½Ğ¶Ğ¸Ğ»Ğ³ÑÑ Ğ³Ò¯Ğ¹Ñ†ÑÑ‚Ğ³ÑÑ…"
        if st.button(btn):
            try:
                # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                data = df[[x_var, m_var, y_var]].apply(pd.to_numeric, errors='coerce').dropna()
                
                if len(data) < 4:
                    st.error("âŒ æœ‰æ•ˆæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œä¸­ä»‹åˆ†æï¼ˆè‡³å°‘éœ€è¦4ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼‰")
                else:
                    # è·¯å¾„ a: X â†’ M
                    X_a = sm.add_constant(data[x_var])
                    model_a = sm.OLS(data[m_var], X_a).fit()
                    a = float(model_a.params[1])
                    
                    # è·¯å¾„ b: M â†’ Y (æ§åˆ¶ X)
                    X_b = sm.add_constant(data[[x_var, m_var]])
                    model_b = sm.OLS(data[y_var], X_b).fit()
                    b = float(model_b.params[m_var])
                    c_prime = float(model_b.params[x_var])
                    
                    # è·¯å¾„ c: X â†’ Y (æ€»æ•ˆåº”)
                    X_c = sm.add_constant(data[x_var])
                    model_c = sm.OLS(data[y_var], X_c).fit()
                    c = float(model_c.params[1])
                    
                    # ä¸­ä»‹æ•ˆåº”
                    indirect = a * b
                    direct = c_prime
                    total = c
                    
                    result_df = pd.DataFrame({
                        'è·¯å¾„': ['a (Xâ†’M)', 'b (Mâ†’Y)', "c' (Xâ†’Yç›´æ¥)", 'c (Xâ†’Yæ€»)', 'ä¸­ä»‹æ•ˆåº” (aÃ—b)'],
                        'ç³»æ•°': [a, b, c_prime, c, indirect],
                        'på€¼': [float(model_a.pvalues[1]), float(model_b.pvalues[m_var]), float(model_b.pvalues[x_var]), float(model_c.pvalues[1]), np.nan]
                    })
                    
                    st.dataframe(result_df, use_container_width=True)
                    
                    st.info(f"""
                    ğŸ“Š ä¸­ä»‹æ•ˆåº”åˆ†æç»“æœï¼š
                    - æ€»æ•ˆåº” c = {c:.4f}
                    - ç›´æ¥æ•ˆåº” c' = {c_prime:.4f}
                    - é—´æ¥æ•ˆåº” aÃ—b = {indirect:.4f}
                    - ä¸­ä»‹æ¯”ä¾‹ = {(indirect/c*100 if c != 0 else 0):.2f}%
                    """)
                    
                    st.session_state.stat_result = f"ä¸­ä»‹æ•ˆåº”ï¼š{x_var}â†’{m_var}â†’{y_var}, é—´æ¥æ•ˆåº”={indirect:.4f}"
                    
                    # AIæ™ºèƒ½åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI æ™ºèƒ½åˆ†æ")
                    
                    with st.spinner("AIæ­£åœ¨åˆ†æç»“æœ..."):
                        result_data = {
                            'x_var': x_var,
                            'm_var': m_var,
                            'y_var': y_var,
                            'a': a,
                            'p_a': float(model_a.pvalues[1]),
                            'b': b,
                            'p_b': float(model_b.pvalues[m_var]),
                            'c': c,
                            'c_prime': c_prime,
                            'indirect': indirect,
                            'mediation_ratio': (indirect/c*100 if c != 0 else 0)
                        }
                        
                        ai_analysis = get_ai_analysis(result_data, "mediation")
                        
                        if ai_analysis:
                            # åˆ¤æ–­ä¸­ä»‹æ•ˆåº”æ˜¯å¦æ˜¾è‘—
                            if model_a.pvalues[1] < 0.05 and model_b.pvalues[m_var] < 0.05:
                                st.success(ai_analysis)
                            else:
                                st.info(ai_analysis)
                        else:
                            st.info("ğŸ’¡ è¯·åœ¨ **ğŸ¤– AI è¾…åŠ©åˆ†æ** ä¸­é…ç½®AIåï¼Œå¯è·å¾—æ™ºèƒ½åˆ†æç»“æœã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œä¸­ä»‹åˆ†ææ—¶å‡ºé”™ï¼š{str(e)}")


